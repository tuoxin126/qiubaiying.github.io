---
layout:     post
title:     Java 操作Kafka 示例
subtitle:   Kafka
date:       2019-02-25
author:     BY tuo
header-img: img/post-bg-centos-web.jpg
catalog: 	 true
tags:
    - LeetCode练习题
---
### 单线程操作
Maven 配置

  		<!-- https://mvnrepository.com/artifact/org.apache.kafka/kafka-clients -->
		<dependency>
			<groupId>org.apache.kafka</groupId>
			<artifactId>kafka-clients</artifactId>
			<version>2.1.1</version>
		</dependency>
		
生产者代码：
```

import java.util.Properties;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerRecord;

public class ProducerDemo2 {
	public static void main(String[] args) {
		Properties props = new Properties();
		// kafka的地址
		props.put("bootstrap.servers",
				"synhadoop100:9092,synhadoop101:9092,synhadoop102:9092,synhadoop103:9092,synhadoop104:9092");
		// acks:消息的确认机制，默认值是0
		// acks=0：如果设置为0，生产者不会等待kafka的响应。
		// acks=1：这个配置意味着kafka会把这条消息写到本地日志文件中，但是不会等待集群中其他机器的成功响应
		// acks=all：这个配置意味着leader会等待所有的follower同步完成。这个确保消息不会丢失，除非kafka集群中所有机器挂掉。这是最强的可用性保证
		props.put("acks", "all");
		// 配置为大于0的值的话，客户端会在消息发送失败时重新发送
		props.put("retries", 0);
		// 当多条消息需要发送到同一个分区时，生产者会尝试合并网络请求。这会提高client和生产者的效率。
		props.put("batch.size", 16384);
		// 在正常负载的情况下, 要想减少请求的数量. 加上一个认为的延迟: 不是立即发送消息, 而是延迟等待更多的消息一起批量发送. 类似TCP中的Nagle算法.
		// 当获得了batch.size的同一partition的消息会立即发送, 不管linger.ms的设置. 假如要发送的消息比较少,
		// 会等待指定的时间以获取更多的消息.
		props.put("linger.ms", 1000);
		// producer可以使用的最大内存来缓存等待发送到server端的消息.
		props.put("buffer.memory", 33554432);
		// 键序列化，默认org.apache.kafka.common.serialization.StringDeserializer
		props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
		// 值序列化，默认org.apache.kafka.common.serialization.StringDeserializer
		props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
    
    // 主题
		String topic = "test";
		Producer<String, String> producer = new KafkaProducer<>(props);
		for (int i = 0; i < 100; i++) {
			producer.send(new ProducerRecord<String, String>(topic, Integer.toString(i), Integer.toString(i)));
		}
		producer.close();
	}
}

```
<p class="copyright-item">
      <a rel="license" href="http://atbug.com/kafka-producer-config/#buffer-memory" target="_blank">Kafka Producer配置解读</a>
</p>

消费者代码：
```
import java.time.Duration;
import java.time.temporal.ChronoUnit;
import java.util.Arrays;
import java.util.Properties;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;

public class AutoCommitConsumerDemo {
	public static void main(String[] args) throws InterruptedException {
		Properties props = new Properties();
		// kafka的地址
		props.put("bootstrap.servers",
				"synhadoop100:9092,synhadoop101:9092,synhadoop102:9092,synhadoop103:9092,synhadoop104:9092");
		// 组名
		// 不同组名可以重复消费。例如你先使用了组名A消费了kafka的1000条数据，但是你还想再次进行消费这1000条数据，并且不想重新去产生，
		// 那么这里你只需要更改组名就可以重复消费了。
		props.put("group.id", "tes1et");
		// 是否自动提交，默认为true。
		props.put("enable.auto.commit", "true");
		// 一次最大拉取的条数。
		props.put("max.poll.records", "100");
		// 键序列化，默认org.apache.kafka.common.serialization.StringDeserializer
		props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
		// 值序列化，默认org.apache.kafka.common.serialization.StringDeserializer。
		props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
		@SuppressWarnings("resource")
		KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
		// 添加读取topic列表
		consumer.subscribe(Arrays.asList("test"));
		Duration duration = Duration.of(1000, ChronoUnit.MILLIS);
		while (true) {
			// timeout(ms): buffer 中的数据未就绪情况下，等待的最长时间，如果设置为0，立即返回 buffer 中已经就绪的数据
			ConsumerRecords<String, String> records = consumer.poll(duration);
			for (ConsumerRecord<String, String> record : records)
				System.out.printf("offset = %d, key = %s, value = %s%n", record.offset(), record.key(), record.value());
			System.out.println("~~~~~~~~~~~~~~~~~~~~~~");
			Thread.sleep(1000);
		}
	}
}

```
开多个 AutoCommitConsumerDemo 的main函数，他们只有一个能读取kafka中的数据因为其group.id 相同。如果将 group.id 设置为不同的值，则多个AutoCommitConsumerDemo 会读取到相同的值，但需要他们都在运行，而不是先运行一个，等第一个拿到数据之后，会想Kafka发送数据已经读取，所以第二再开始的时候数据已经没了，并不能读取到。他这个里面有一个确认机制，一旦开启非自动确认，在程序内部没有确认的情况下，数据不会被认为读取过，就不会从Kafka中移除。

### 多线程同时读取代码
Maven需要配置：
	
		<dependency>
			<groupId>org.apache.kafka</groupId>
			<artifactId>kafka_2.10</artifactId>
			<version>0.10.2.0</version>
		</dependency>


多线程同时读取我现在了解的有俩种方式，第一只就是多topic，这个比较明了，一个写、一个读，写多个topic每个线程维护自己的topic。第二种是在同一个topic下建立多个partition，每个线程维护自己对应的topic下的partition.文章主要实现第二种方式，第一种大家可以根据上面的单线程进行修改即可得。

<p class="copyright-item">
      <a rel="license" href="https://github.com/tuoxin126/tuoxin126.github.io/blob/master/less/KafkaUtils.java" target="_blank">KafkaUtils.java 生产者需要的工具类</a>
</p>

生产者代码：
```

import java.util.Properties;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerRecord;

public class ProducerDemo {
	public static void main(String[] args) {
		Properties props = new Properties();
		// kafka的地址
		props.put("bootstrap.servers",
				"synhadoop100:9092,synhadoop101:9092,synhadoop102:9092,synhadoop103:9092,synhadoop104:9092");
		// acks:消息的确认机制，默认值是0
		// acks=0：如果设置为0，生产者不会等待kafka的响应。
		// acks=1：这个配置意味着kafka会把这条消息写到本地日志文件中，但是不会等待集群中其他机器的成功响应
		// acks=all：这个配置意味着leader会等待所有的follower同步完成。这个确保消息不会丢失，除非kafka集群中所有机器挂掉。这是最强的可用性保证
		props.put("acks", "all");
		// 配置为大于0的值的话，客户端会在消息发送失败时重新发送
		props.put("retries", 0);
		// 当多条消息需要发送到同一个分区时，生产者会尝试合并网络请求。这会提高client和生产者的效率。
		props.put("batch.size", 16384);
		// 在正常负载的情况下, 要想减少请求的数量. 加上一个认为的延迟: 不是立即发送消息, 而是延迟等待更多的消息一起批量发送. 类似TCP中的Nagle算法.
		// 当获得了batch.size的同一partition的消息会立即发送, 不管linger.ms的设置. 假如要发送的消息比较少,
		// 会等待指定的时间以获取更多的消息.
		props.put("linger.ms", 1000);
		// producer可以使用的最大内存来缓存等待发送到server端的消息.
		props.put("buffer.memory", 33554432);
		// 键序列化，默认org.apache.kafka.common.serialization.StringDeserializer
		props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
		// 值序列化，默认org.apache.kafka.common.serialization.StringDeserializer
		props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
		String topic = "test";
		Producer<String, String> producer = new KafkaProducer<>(props);
		for (int j = 0; j < 3; j++) {
			// 创建partition ，要提前创，虽然producer.send函数说是会自动创建topic和partition。
			// 但是实际测试发现，其对于 partition 大于0的写入数据时时间会很漫长，而且没有正确send到kafka结果
			KafkaUtils.createTopic(topic, j, 0, props);
			for (int i = 0; i < 100; i++) {
				producer.send(new ProducerRecord<String, String>(topic, j, Integer.toString(i), Integer.toString(i)));
				System.out.println(j + "---------------------------");
			}
		}
		producer.close();
	}
}

```

